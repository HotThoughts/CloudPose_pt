data:
  # The dir name where data stores
  dataset: mydataset
  tfrecord_dir: "mydataset/FPS1024"
  num_point: 1024
  num_class: 21
  split: [0.8, 0.1, 0.1]
  train_dir: "my_train"
  val_dir: "my_val"
  test_dir: "my_test"
  # For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required. This will need > 18GB memory
  shuffle: 1000000
  total_num_items: 879749

train:
  epochs: 1
  max_epochs: 10
  batch_size: 32
  # Initial learning rate
  lr: 0.001
  # Which epochs to decay the learning rate
  lr_decay_steps: [80, 120, 160]
  lr_decay_rate: [0.1, 0.1, 0.1]
  # Optimization L2 weight decay
  weight_decay: 0
  # Preiod of BN decay in epochs
  bn_decay_step: 40
  # Decay rate for BN decay
  bn_decay_rate: 0.5
  # Adam or gd
  optimizer: adam
  # Model checkpoint path
  checkpoint_path: ""
  train_dir: "small_train"
  val_dir: "small_val"
  test_dir: "small_test"
  log_dir: "logs/small"
  # Overwriting existing log and dump folders
  overwrite: true

process:
  thresh: 0.98
  bow: 15000
